import json
import matplotlib.pyplot as plt
import random
import re
from typing import List, Tuple
import numpy as np



def get_answer_distribution(sampled_sequences: List[str]) -> List[Tuple[str, int]]:
    """Get the answer distribution from the sampled sequences
    
    Args:
        sampled_sequences (List[str]): Sampled sequences from the model
        dataset_name (str): Name of the dataset
        
    Returns:
        List[Tuple[str, int]]: The answer distribution
    """
    # Clean the answers and remove empty strings
    answers = [_answer_cleaning(sequence) for sequence in sampled_sequences]
    # No longer needed
    # answers = [answer.strip() for answer in answers if answer != ""]
    # If no answers are present, return an empty list
    if len(answers) == 0:
        return []
    # Get the answer distribution

    answers, answer_counts = np.unique(answers, return_counts=True)
    distribution = list(zip([str(answer) for answer in answers], [answer_count/len(sampled_sequences) for answer_count in answer_counts]))
    return sorted(distribution, key=lambda x: x[1], reverse=True)

def get_majority_vote_answer(sampled_sequences: List[str]) -> str:
    """Get the majority vote answer from the sampled sequences

    Args:
        sampled_sequences (List[str]): Sampled sequences from the model
        dataset_name (str): Name of the dataset

    Returns:
        str: The majority vote answer
    """
    
    answer_distribution = get_answer_distribution(sampled_sequences)
    
    # If no answers are present, return an empty string
    if len(answer_distribution) == 0:
        return ""
    
    return answer_distribution[0][0]

def _answer_cleaning(sequence: str) -> str:
    """Extract the answer from the generated sequence

    Args:
        sequence (str): Sequence generated by the model
        dataset_name (str): Name of the dataset

    Returns:
        str: The extracted answer
    """
    is_mathematical = True
    # Extract the answer from the sequence based on the dataset type
    if is_mathematical:
        return _mathematical_answer_cleaning(sequence)
    else:
        return sequence.strip().split()[-1]

def _mathematical_answer_cleaning(sequence: str) -> str:
    """Extract the mathematical answer from the generated sequence

    Args:
        sequence (str): Sequence generated by the model

    Returns:
        str: The extracted mathematical answer
    """
    # Extract the numerical answer from the sequence
    answer = [s for s in re.findall(r'-?\d+\.?\d*', sequence.replace(",", ""))]
    # Return the answer if present, else return an empty string
    if len(answer) == 0:
        return -np.inf
    # Handle the case where the answer ends with a period
    return float(answer[-1][:-1] if answer[-1].endswith(".") else answer[-1])

# GREEDY & BASELINE GSM8K GEMMA-2B
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/greedy__gsm8k__gemma-2b__output.json', 'r') as file:
    greedy_gemma2b_data = json.load(file)
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/baseline__gsm8k__gemma-2b__output.json', 'r') as file:
    baseline_gemma2b_data = json.load(file)

#GREEDY & BASELINE GSM8K GEMMA 7-B
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/greedy__gsm8k__gemma-7b__output.json', 'r') as file:
    greedy_gemma7b_data = json.load(file)
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/baseline__gsm8k__gemma-7b__output.json', 'r') as file:
    baseline_gemma7b_data = json.load(file)

#GREEDY & BASELINE GSMK GPT2-LARGE
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/greedy__gsm8k__gpt2-large__output.json', 'r') as file:
    greedy_gpt2_data = json.load(file)
with open('/users/poojithapenta/desktop/COMPSCI-685-PROJECT/src/Plots/baseline__gsm8k__gpt2-large__output.json', 'r') as file:
    baseline_gpt2_data = json.load(file)

def accuracy_function(data,method):
    accuracies=[]
    if method=='baseline':
        samples=[5,10,15,20,25,30,35,40]
        for i in samples:
            accuracy=0
            for item in data:
                sampled_data = random.sample(item['generated_sequences'], i)
                x=get_majority_vote_answer(sampled_data)
                #print(f"Sampled Majority Vote: {x}, Ground Truth: {item['ground_truth_answer']}")
                if (float(item['ground_truth_answer'].replace(',', '')) == float(x.replace(',', ''))):
                    accuracy+=1
                #print(accuracy)
            accuracy_total= accuracy/len(data)
            accuracies.append(accuracy_total)
            #print(accuracies)
        #total_accuracy = sum(1 for item in data if item['ground_truth_answer'] == item['majority_vote_answer'])
      
    else:
        samples=[5,10,15,20,25,30,35,40]
        for i in samples:
            total_accuracy = sum(1 for item in data if item['ground_truth_answer'] == item['majority_vote_answer'])
            accuracy_total= total_accuracy/len(data)
            accuracies.append(accuracy_total)
    return {
        'sample_paths': samples,
        'accuracies': accuracies
    }
accuracies_greedy_gemma_2b=accuracy_function(greedy_gemma2b_data, method='greedy')
accuracies_baseline_gemma_2b=accuracy_function(baseline_gemma2b_data, method='baseline')
accuracies_greedy_gemma_7b=accuracy_function(greedy_gemma7b_data,method='greedy' )
accuracies_baseline_gemma_7b=accuracy_function(baseline_gemma7b_data, method='baseline')
accuracies_greedy_gpt2=accuracy_function(greedy_gpt2_data,  method='greedy' )
accuracies_baseline_gpt2=accuracy_function(baseline_gpt2_data,  method='baseline')


plt.figure(figsize=(6, 6))

plt.plot([5,10,15,20,25,30,35,40], accuracies_baseline_gpt2['accuracies'], color='red', label='Baseline', marker='o')  
plt.plot([5,10,15,20,25,30,35,40], accuracies_greedy_gpt2['accuracies'], color='blue', label='Greedy', marker='o')

plt.title('Accuracy vs Number of Sampled Reasoning Paths - GPT2-LARGE')
plt.xlabel('Number of Sampled Reasoning Paths')
plt.ylabel('Accuracy')
plt.xticks([5,10,15,20,25,30,35,40])
plt.grid(True)
plt.legend() 
plt.show()